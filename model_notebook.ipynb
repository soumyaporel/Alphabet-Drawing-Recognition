{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import string\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "                                            torchvision.transforms.ToTensor()])\n",
    "\n",
    "alphabet_set = torchvision.datasets.ImageFolder(root='./AlphabetDataset/',\n",
    "                                                transform=transform)\n",
    "\n",
    "print(\"Class names and corresponding labels:\\n\", alphabet_set.class_to_idx)\n",
    "print(\"Total number of instances:\", len(alphabet_set.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = alphabet_set[8269] # label b/w 0, 26\n",
    "\n",
    "alphabet_mapper = list(string.ascii_uppercase) # ['A', 'B',..., 'Z']\n",
    "\n",
    "print('label:', alphabet_mapper[label])\n",
    "plt.imshow(image.numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in alphabet_set:\n",
    "    image, label = i\n",
    "    if alphabet_mapper[label] == 'B':\n",
    "        c += 1\n",
    "        plt.imshow(image[0], cmap='gray')\n",
    "        plt.show()\n",
    "    if c > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        number_of_classes = 26\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=(2, 2))\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
    "        self.fc2 = torch.nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = torch.nn.Linear(in_features=84, out_features=number_of_classes)    \n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dpt = torch.nn.Dropout(0.4) # 40% probability\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t = self.conv1(t) # 1 * 28 * 28 -> 6 * 28 * 28 \n",
    "        t = self.relu(t)\n",
    "\n",
    "        t = self.max_pool(t) # 6 * 14 * 14 \n",
    "        \n",
    "        t = self.conv2(t) # 16 * 10 * 10\n",
    "        t = self.relu(t)\n",
    "\n",
    "        t = self.max_pool(t) # 16 * 5 * 5\n",
    "        \n",
    "        t = self.dpt(t)\n",
    "        \n",
    "        t = t.reshape(-1, 16 * 5 * 5) # flatten in order to feed to the FC layers \n",
    "\n",
    "        t = self.fc1(t) # 400 -> 120\n",
    "        t = self.relu(t)\n",
    "\n",
    "        t = self.fc2(t) # 120 -> 84\n",
    "        t = self.relu(t)\n",
    "        \n",
    "        t = self.fc3(t) # 84 -> 26 (number of classes)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "total_epochs = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "net = Network() #create Object\n",
    "net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate) \n",
    "criterion = torch.nn.CrossEntropyLoss() # Defining the loss calculating method for our Network object. We use cross entropy loss.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(alphabet_set, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "net = net.train()\n",
    "\n",
    "for epoch in range(1, total_epochs + 1):\n",
    "\n",
    "    batch_count = 0\n",
    "    \n",
    "    for batch in train_loader: #Get a Batch\n",
    "        \n",
    "        batch_count += 1\n",
    "\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = net(images) #Pass Batch; preds.shape -> (batch_size, number_of_classes)\n",
    "        loss = criterion(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() #Calculate Gradients\n",
    "        optimizer.step() #Update Weights\n",
    "        \n",
    "        print(f'epoch: {epoch}/{total_epochs} | batch: {batch_count}/{len(train_loader)} | correct preds: {preds.argmax(dim=1).eq(labels).sum().item()}/{len(labels)}')\n",
    "\n",
    "    print('Epoch:', epoch, '| Current loss:', loss.item())                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./saved_models/my_cnn_model.pt\" \n",
    "torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ten_fold_cv(the_dataset, total_epochs, learning_rate, batch_size):\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True) # create the 10 folds\n",
    "\n",
    "    total_accuracy = 0\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(the_dataset): # each fold\n",
    "        train_set = torch.utils.data.Subset(the_dataset, train_index) \n",
    "        test_set = torch.utils.data.Subset(the_dataset, test_index) \n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        net = Network() # a new object is created for each fold\n",
    "        net = net.to(device)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate) # specific to this net object of this fold \n",
    "        criterion = torch.nn.CrossEntropyLoss() # Defining the loss calculating method for our Network object. We use cross entropy loss.\n",
    "\n",
    "        for epoch in range(1, total_epochs + 1): \n",
    "            \n",
    "            batch_count = 0\n",
    "            \n",
    "            for batch in train_loader: # each Batch (0 to total_instances/batch_size)\n",
    "                \n",
    "                batch_count += 1\n",
    "                \n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                preds = net(images) # Pass Batch (Forward pass)\n",
    "                loss = criterion(preds, labels) \n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward() # Calculate Gradients\n",
    "                optimizer.step() # Update Weights\n",
    "                \n",
    "                print(f'fold: {fold}/10 | epoch: {epoch}/{total_epochs} | batch: {batch_count}/{len(train_loader)} | correct preds: {preds.argmax(dim=1).eq(labels).sum().item()}/{len(labels)}')\n",
    "            \n",
    "            print(f'\\nfold: {fold}/10 | epoch: {epoch}/{total_epochs} | loss: {loss.item()}\\n')\n",
    "            # print()\n",
    "\n",
    "        #testing\n",
    "        test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "        total_correct_predictions = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = net(images)\n",
    "            total_correct_predictions += preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "        accuracy = total_correct_predictions / len(test_set)\n",
    "        \n",
    "        \n",
    "        print(f'fold: {fold}/10 | correct predictions: {total_correct_predictions}/{len(test_set)} | accuracy: {accuracy}')\n",
    "        print()\n",
    "\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "\n",
    "    final_accuracy = total_accuracy / 10\n",
    "    print('\\n\\nFinal result:')\n",
    "    print('Accuracy:', final_accuracy)\n",
    "    return final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ten_fold_cv(the_dataset=alphabet_set, total_epochs=2, learning_rate=0.001, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
